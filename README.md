# Northcoders News API by Sam Styles

This project establishes a psql database and a series of endpoints that can be used to query and add to the data.

The project was initially established as part of the final BackEnd sprint in the Northcoders course, August 2020.

The project was developed using `Node.js` [v14.4.0] and `VS Code`. `Knex` has been used as a 'query-builder' to manage the interface with the psql database, which is built using `postgres` [v12.3]. The server is established using `Express`. `Jest` and `Supertest` have been used for testing.

The app has been published to Heroku at this location: `https://nc-hosting-samstyles84.herokuapp.com/api`

# Features

The database containts data tables relating to `topics`, `users`, `articles` and `comments`. Upwards migrations are carried out in that order when seeding the database.

Separate "test" and "dev" data is included in the relevant "./db/" directories.

Endpoints have been established that allow users to view and amend the data as described in the `API Reference` section below.

# API

The API allows access to the following endpoints. For more details refer to the "endpoints.json" file included.

"GET /api": serves up a json representation of all the available endpoints of the api
"GET /api/topics": serves an array of all topics
"GET /api/users/:username": serves the corresponding username object
"GET /api/articles": serves an array of all articles, with no bodies
"GET /api/articles/:article_id": serves the corresponding article object, including the body
"PATCH /api/articles/:article_id": updates the vote count of the corresponding article and responds with the updated article object
"POST /api/articles/:article_id/comments": posts a comment about the corresponding article and returns the comment
"GET /api/articles/:article_id/comments": returns an array of all of the comments relating to the corersponding article
"PATCH /api/comments/:comment_id": updates the vote count of the corresponding comment and responds with the updated comment object
"DELETE /api/comments/:comment_id": deletes a comment from the database returning status code 204 if successful

# Architecture

The code has been developed using MVC architecture.

"app.js" identifies the correct router for the specific query. Where Heroku is used, incoming Heroku queries are identified by the "listen.js" file.

All well-formed queries are directed through the "/api" router into the relevant route. Routers can be found in the "./routes" folder. Each router passes well-formed queries on to the relevant Controller.

The Controllers are purely used to pass information between the Routers and the Models. Controllers have been grouped into files according to their API routing and can be found in "./controllers".

The Models interface with the database and also (typically) handle any custom error handling. Models have been grouped into files according to their API routing and can be found in"./models".

The models return their results back to the controllers, which return them on to the Client.

Errors are caught by `.catch` statements within the Controllers, and passed to the Error-Handling functions via "app.js" (see below for further information).

# Error-Handling

Error-Handling Functions are contained in "./errors/index.js".

The server can return the following errors:

400: Bad request (These are typically reflective of bad queries to the psql database.)

404: Invalid path (These can be generated by either:

- a non-existent end-point (e.g. "/apj/topicz"), which are handled by the "badPathError" function, or
- a well-formed request that does not return any results, which are handled by custom errors using Promise.reject, typically within the relevant model file)

405: Invalid method (e.g. attempting a post request to an enpoint that does not allow this functionality)

422: Unprocessable entity (this error is generated by a well-formed request that could not be processed by the PSQL database. It is typcially caused by a POST request associated with a resource that doesn't exist (e.g. trying to attribute a new comment to a user that does not exist))

500: Server error (this error code will be returned if the error does not fall into the categories above)

# Environments

Three environments are used within the app:

`test` for testing purposes
`development` for development purposes
`production` for deployment to Heroku

Unless otherwise specified, the environment will default to `development`.

# Installation

To clone the project, run `git clone https://github.com/samstyles84/be-nc-news`.

Dependencies are listed in the package.json file. To install dependencies, run "npm install".

The user will need to create their own knexfile.js (see Knexfile Configuration, below).

To initialise (or re-initialise) the databses, run "npm run setup-dbs". This will DROP both the test and development databases (if they exist) and then CREATE new (empty) versions of each.

To seed the development database, type "npm run seed" at the command line. This will rollback and then migrate the development database to the latest migration (i.e. clean the development database).

To run the test suites, use "npm test" at the command line. This will:

- set the environment to "test"
- run "knex.seed.run" before each test in `app.test.js`.
- this causes the file "./db/seeds/seed.js" to be run. This file rollsback the test database, and then runs all of the migrations, so that the db is clean before each test.
- runs the tests

# Knexfile Configuration

The user will need to create their own "./knexfile.js" to determine the configuration for Knex. Refer to http://knexjs.org/#Installation-client for Knex documentation.

This file should use a global variable (`process.env.NODE_ENV`) to set the correct environment (`test`, `development` or `production`). This variable also determines which version of the database should be used (`test`, for testing, `development` for development and the `Heroku` db for production).

Note that "Connection.js" is also used to manage the knex connections, switching between test / development / production environments as required.

Below are the resulting dbConfig files for each enviroment, for information:

`Test`:
{
connection: { database: 'nc_news_test' },
client: 'pg',
migrations: { directory: './db/migrations' },
seeds: { directory: './db/seeds' }
}

`Development`:
{
connection: { database: 'nc_news' },
client: 'pg',
migrations: { directory: './db/migrations' },
seeds: { directory: './db/seeds' }
}

`Production`:
{ client: "pg", connection: process.env.DATABASE_URL }

Non Mac OS users will need to add their username and password within these files.

An optional custom console log command can be introduced within "knexfile.js" to suppress knex warnings related to FSMigrations:

       const log = console.log;
       console.log = (...args) => {
         if (!/FsMigrations/.test(args[0])) log(...args);
       };

# Tests

The code was developed using Test Driven Development (TDD) and therefore a comprehensive suite of test functions has been included.

Testing has been carried out using the `Jest` package. `Supertest` is also required, to simulate testing of the server.

Tests for app functionality are included within `./__tests__/app.test.js`.

Tests for utility functions (such as formatting data) are included within `./__tests__/utils.test.js`.

Scripts in the package.json file ensure that the "test" data will be used when tests are being run. Scripts also ensure that the test database is migrated to the latest version before each test, and rolled back after each test.

# Possible further development

#### Pagination

To make sure that an API can handle large amounts of data, it is often necessary to use **pagination**. Head over to [Google](https://www.google.co.uk/search?q=cute+puppies), and you will notice that the search results are broken down into pages. It would not be feasible to serve up _all_ the results of a search in one go. The same is true of websites / apps like Facebook or Twitter (except they hide this by making requests for the next page in the background, when we scroll to the bottom of the browser). We can implement this functionality on our `/api/articles` and `/api/comments` endpoints.

```http
GET /api/articles
```

- Should accepts the following queries:
  - `limit`, which limits the number of responses (defaults to 10)
  - `p`, stands for page which specifies the page at which to start (calculated using limit)
- add a `total_count` property, displaying the total number of articles (**this should display the total number of articles with any filters applied, discounting the limit**)

---

```http
GET /api/articles/:article_id/comments
```

Should accept the following queries:

- `limit`, which limits the number of responses (defaults to 10)
- `p`, stands for page which specifies the page at which to start (calculated using limit)

#### More Routes

```http
POST /api/articles

DELETE /api/articles/:article_id

POST /api/topics

POST /api/users
GET /api/users
```

# Instructions for hosting (for future reference):

# Hosting a PSQL DB using Heroku

There are many ways to host applications like the one you have created. One of these solutions is Heroku. Heroku provides a service that you can push your code to and it will build, run and host it. Heroku also allows for easy database integration. Their [documentation](https://devcenter.heroku.com/articles/getting-started-with-nodejs) is excellent, so take a look at that. This document is essentially a more condensed, specific version of the steps described in the Heroku docs.

## 1. Install the Heroku CLI

On macOS:

```bash
brew tap heroku/brew && brew install heroku
```

...or Ubuntu:

```bash
sudo snap install --classic heroku
```

## 2. Create a Heroku App

Log into Heroku using their command line interface:

```bash
heroku login
```

Create an app in an active git directory. Doing this in the folder where your server exists is a good start, as this is what you will be hosting.

```bash
heroku create your-app-name
```

Here `your-app-name` should be the name you want to give your application. If you don't specify an app name, you'll get a random one which can sometimes be a bit iffy.

This command will both create an app on Heroku for your account. It will also add a new `remote` to your git repository.
Check this by looking at your git remotes:

```bash
git remote -v
```

## 3. Push Your code up to Heroku

```bash
git push heroku master
```

## 4. Creating a Hosted Database

Go to the heroku site and log in.

- Select your application
- `Configure Add-ons`
- Choose `Heroku Postgres`

The free tier will be adequate for our purposes. This will provide you with a `postgreSQL` pre-created database!

Check that the database exists. Click `settings` on it, and view the credentials. Keep an eye on the URI. Don't close this yet!

## 5. Seeding the Production Database

Check that your database's url is added to the environment variables on Heroku:

```bash
heroku config:get DATABASE_URL
```

If you are in your app's directory, and the database is correctly linked as an add on to Heroku, it should display a DB URI string that is exactly the same as the one in your credentials.

At the top of your `knexfile.js`, add the following line of code:

```js
const { DB_URL } = process.env;
```

Next, add a `production` key to the `customConfigs` object in your `knexfile.js`. Add in the `DB_URL` as `connectionString` into the connection object with an additional `ssl.rejectUnauthorized` property set to false:

```js
const { DB_URL } = process.env;
// ...
const customConfigs = {
  // ...
  production: {
    connection: {
      connectionString: DB_URL,
      ssl: {
        rejectUnauthorized: false,
      },
    },
  },
};
// ...
```

It is critical to set the `ssl.rejectUnauthorized` property to `false`, otherwise we will not be able to connect to the hosted database from your local machine.

In your `./db/data/index.js` add a key of production with a value of your development data in your data object. Something like:

```js
const data = { test, development, production: development };
```

This is will ensure your production DB will get seeded with the development data.

In your `package.json`, add the following keys to the scripts:

```json
{
  "scripts": {
    "seed:prod": "NODE_ENV=production DB_URL=$(heroku config:get DATABASE_URL) knex seed:run",
    "migrate-latest:prod": "NODE_ENV=production DB_URL=$(heroku config:get DATABASE_URL) knex migrate:latest",
    "migrate-rollback:prod": "NODE_ENV=production DB_URL=$(heroku config:get DATABASE_URL) knex migrate:rollback"
  }
}
```

Each of these will establish an environment variable called `DB_URL`, and set it to whatever heroku provides as your DB URL. It is essential that you do this as the DB URL may change! This deals with a lack of predictability on heroku's end.

Make sure to **run the seed prod script** from your `package.json`:

```bash
npm run seed:prod
```

## 6. Connect To The Hosted Database when on Heroku

Change your connection file to look something like this:

```js
const ENV = process.env.NODE_ENV || "development";
const knex = require("knex");

const dbConfig =
  ENV === "production"
    ? { client: "pg", connection: process.env.DATABASE_URL }
    : require("../knexfile");

module.exports = knex(dbConfig);
```

It should check whether you're in production, and if you are, it should connect to the production database. Otherwise it will connect to the (`.gitignore`'d) knex file.

## 7. Use Heroku's PORT

In `listen.js`, make sure you take the PORT off the environment object if it's provided, like so:

```js
const { PORT = 9090 } = process.env;

app.listen(PORT, () => console.log(`Listening on ${PORT}...`));
```

## 8. Add a start script

Make sure your package.json has this as a start script:

```json
"start": "node listen.js",
```

Commit your changes, and push to heroku master.

```bash
git push heroku master
```

## 9. Review Your App

```bash
heroku open
```

Any issues should be debugged with:

```bash
heroku logs --tail
```
